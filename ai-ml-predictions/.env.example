# API Settings
API_V1_STR=/api/v1
PROJECT_NAME=AI/ML Predictions Service
VERSION=1.0.0
DEBUG=False

# Server Settings
HOST=0.0.0.0
PORT=3004
WORKERS=4
RELOAD=True

# Database Settings
POSTGRES_HOST=localhost
POSTGRES_PORT=5434
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=ai_ml_predictions

# Redis Settings
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# MLflow Settings
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT_NAME=production

# Service Integration
LOGISTICS_ENGINE_URL=http://localhost:5050
INVENTORY_SYNC_URL=http://localhost:5051

# Security Settings
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Cache Settings
PREDICTION_CACHE_TTL=3600
FEATURE_CACHE_TTL=1800

# Model Settings
DEFAULT_MODEL_VERSION=latest
MODEL_CONFIDENCE_THRESHOLD=0.8
BATCH_SIZE=32

# Monitoring Settings
ENABLE_METRICS=True
METRICS_PORT=8000
LOG_LEVEL=INFO

# Application Settings
APP_NAME=AI/ML Predictions Service

# Predictions Database Settings
PREDICTIONS_DB_HOST=localhost
PREDICTIONS_DB_PORT=5432
PREDICTIONS_DB_USER=postgres
PREDICTIONS_DB_PASS=postgres
PREDICTIONS_DB_NAME=predictions

# Logistics Database Settings
LOGISTICS_DB_HOST=localhost
LOGISTICS_DB_PORT=5432
LOGISTICS_DB_USER=postgres
LOGISTICS_DB_PASS=postgres
LOGISTICS_DB_NAME=logistics

# Database Pool Settings
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30
DB_ECHO=False

# Redis Settings
REDIS_DB=0
ENABLE_CACHE=True

# Model Settings
MODEL_PATH=models/
MODEL_VERSION=v1